{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD5uNQeIfGpw",
        "outputId": "36f90a99-aee0-4245-82c9-afb28255934c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6c75b9d170>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SEED = 7\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspiracja: https://datahacker.rs/019-siamese-network-in-pytorch-with-application-to-face-similarity/"
      ],
      "metadata": {
        "id": "Cy6c__LZmv3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_normal_vectors(mean, std_dev, size, dimension):\n",
        "    A = np.random.normal(loc=mean, scale=std_dev, size=(size, dimension))\n",
        "    B = np.random.normal(loc=mean, scale=std_dev, size=(size, dimension))\n",
        "    return A, B\n",
        "\n",
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self, vectors_A, vectors_B):\n",
        "        self.vectors_A = vectors_A\n",
        "        self.vectors_B = vectors_B\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.vectors_A)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        vector_A = torch.FloatTensor(self.vectors_A[index])\n",
        "        vector_B = torch.FloatTensor(self.vectors_B[index])\n",
        "        label = torch.norm(vector_A - vector_B)\n",
        "\n",
        "        return vector_A, vector_B, label"
      ],
      "metadata": {
        "id": "RHjAoDZffNhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        # Setting up the Fully Connected Layers\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(256, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # In this function, we pass in both vectors and obtain both vectors\n",
        "        # which are returned\n",
        "        output1 = self.fc1(input1)\n",
        "        output2 = self.fc1(input2)\n",
        "\n",
        "        return output1, output2"
      ],
      "metadata": {
        "id": "aoYte2o9mf0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseLoss(nn.Module):\n",
        "  # pomysł z funkcją contrastive loss\n",
        "  # def __init__(self, margin=2.0):\n",
        "  #     super(SiameseLoss, self).__init__()\n",
        "  #     self.margin = margin\n",
        "\n",
        "  # def forward(self, output1, output2, label):\n",
        "  #   # Calculate the euclidean distance and calculate the contrastive loss\n",
        "  #   euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
        "\n",
        "  #   loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "  #                                 (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "\n",
        "  #   return loss_contrastive\n",
        "    def __init__(self):\n",
        "        super(SiameseLoss, self).__init__()\n",
        "\n",
        "    def forward(self, output1, output2, target):\n",
        "        euclidean_distance = torch.sqrt(torch.sum(torch.pow(output1 - output2, 2), 1))\n",
        "        loss = nn.MSELoss()(euclidean_distance, target)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "sCvD8nfHmsHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generowanie wektorów w przestrzeni DIM wymiarowej z liczbą próbek równą SIZE\n",
        "DIM = 5\n",
        "SIZE = 10000\n",
        "vectors_A, vectors_B = generate_normal_vectors(0, 1, SIZE, DIM)\n",
        "siamese_dataset = SiameseNetworkDataset(vectors_A, vectors_B)\n",
        "\n",
        "# Testowanie dostępu do elementów w klasie Dataset\n",
        "for i in range(3):\n",
        "    sample = siamese_dataset[i]\n",
        "    print(\"Wektor A:\", sample[0])\n",
        "    print(\"Wektor B:\", sample[1])\n",
        "    print(\"Etykieta:\", sample[2])\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpUZ9ODtfbS3",
        "outputId": "65775d43-a704-4ee1-a08c-16420d73e9a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wektor A: tensor([-0.2970,  1.8194,  0.6723, -0.5436,  0.2082])\n",
            "Wektor B: tensor([-1.2174, -1.9320, -0.3307,  0.0312, -1.1086])\n",
            "Etykieta: tensor(4.2415)\n",
            "\n",
            "\n",
            "Wektor A: tensor([-0.4336, -2.4398, -0.2295, -0.1531, -1.5420])\n",
            "Wektor B: tensor([ 0.8149, -0.2361,  1.6607, -0.6218,  0.0985])\n",
            "Etykieta: tensor(3.5915)\n",
            "\n",
            "\n",
            "Wektor A: tensor([ 0.7187,  0.0343, -1.3620,  0.5158,  0.9281])\n",
            "Wektor B: tensor([-2.8004, -0.7567,  0.4151, -1.6915, -2.0897])\n",
            "Etykieta: tensor(5.4906)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Podział na zbiór uczący, walidacyjny i testowy\n",
        "dataset_size = len(siamese_dataset)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = int(0.1 * dataset_size)\n",
        "test_size = dataset_size - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(siamese_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Indeksy dla SubsetRandomSampler\n",
        "train_indices = list(range(train_size))\n",
        "val_indices = list(range(train_size, train_size + val_size))\n",
        "test_indices = list(range(train_size + val_size, dataset_size))\n",
        "\n",
        "# Samplery dla DataLoader\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "# DataLoader\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(siamese_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "val_loader = DataLoader(siamese_dataset, batch_size=batch_size, sampler=val_sampler)\n",
        "test_loader = DataLoader(siamese_dataset, batch_size=batch_size, sampler=test_sampler)\n"
      ],
      "metadata": {
        "id": "Ypo4GahrjCNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = SiameseNetwork(DIM).to(device)\n",
        "criterion = SiameseLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr = 0.0005 )"
      ],
      "metadata": {
        "id": "LdkmbSlfm1JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = []\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "iteration_number = 0\n",
        "\n",
        "# Iterate through the epochs\n",
        "for epoch in range(50):\n",
        "\n",
        "    # Training\n",
        "    for i, (vec1, vec2, label) in enumerate(train_loader, 0):\n",
        "        vec1, vec2, label = vec1.to(device), vec2.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output1, output2 = net(vec1, vec2)\n",
        "        loss_siamese = criterion(output1, output2, label)\n",
        "        loss_siamese.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    net.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, (val_vec1, val_vec2, val_label) in enumerate(val_loader, 0):\n",
        "            val_vec1, val_vec2, val_label = val_vec1.to(device), val_vec2.to(device), val_label.to(device)\n",
        "            val_output1, val_output2 = net(val_vec1, val_vec2)\n",
        "            val_loss += criterion(val_output1, val_output2, val_label).item()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)  # Calculate the average validation loss\n",
        "    net.train()  # Set the model back to training mode\n",
        "\n",
        "    # Print and store training and validation loss every 10 epochs\n",
        "    if (epoch+1) % 2 == 0 or epoch == 0:\n",
        "        print(f\"Epoch number {epoch+1:<5} Training loss {loss_siamese.item():.4f} Validation loss {val_loss:.4f}\")\n",
        "        iteration_number += 2\n",
        "        counter.append(iteration_number)\n",
        "        train_loss_history.append(loss_siamese.item())\n",
        "        val_loss_history.append(val_loss)\n",
        "\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for i, (test_vec1, test_vec2, test_label) in enumerate(test_loader, 0):\n",
        "        test_vec1, test_vec2, test_label = test_vec1.to(device), test_vec2.to(device), test_label.to(device)\n",
        "        test_output1, test_output2 = net(test_vec1, test_vec2)\n",
        "        test_loss += criterion(test_output1, test_output2, test_label).item()\n",
        "print(f\"\\nTest loss {test_loss:.4f}\")\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.plot(counter, train_loss_history, label='Training Loss')\n",
        "plt.plot(counter, val_loss_history, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3YU1YMnDtYdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "DIM = 5\n",
        "SEED = 7\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "def generate_normal_vectors(mean, std_dev, size, dimension):\n",
        "    A = np.random.normal(loc=mean, scale=std_dev, size=(size, dimension))\n",
        "    B = np.random.normal(loc=mean, scale=std_dev, size=(size, dimension))\n",
        "    return A, B\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(DIM, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = F.relu(self.fc1(x1))\n",
        "        x1 = F.relu(self.fc2(x1))\n",
        "        x2 = F.relu(self.fc1(x2))\n",
        "        x2 = F.relu(self.fc2(x2))\n",
        "        distance = torch.abs(x1 - x2)\n",
        "        distance = self.fc3(distance)\n",
        "        return distance\n",
        "\n",
        "# Create an instance of the SiameseNetwork\n",
        "siamese_net = SiameseNetwork()\n",
        "siamese_net.to(device)\n",
        "\n",
        "# Create a dataset class\n",
        "class SiameseDataset(Dataset):\n",
        "    def __init__(self, A, B):\n",
        "        self.A = A\n",
        "        self.B = B\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.A)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.A[idx], self.B[idx]\n",
        "\n",
        "\n",
        "# Create a dataset instance\n",
        "A, B = generate_normal_vectors(0, 1, 10000, DIM)\n",
        "dataset = SiameseDataset(A, B)\n",
        "\n",
        "# Split the dataset into train, test and validation sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = int(0.1 * len(dataset))\n",
        "val_size = len(dataset) - train_size - test_size\n",
        "train_dataset, test_dataset, val_dataset = random_split(dataset, [train_size, test_size, val_size])\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(siamese_net.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model with validation every 10 epochs\n",
        "num_epochs = 50\n",
        "\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "counter = []\n",
        "for epoch in range(num_epochs):\n",
        "    for A, B in train_loader:\n",
        "        A = A.to(device).float()  # Convert A to float data type\n",
        "        B = B.to(device).float()  # Convert B to float data type\n",
        "        optimizer.zero_grad()\n",
        "        outputs = siamese_net(A, B).squeeze()\n",
        "        loss = criterion(outputs, torch.norm(A - B, dim=1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch % 2 == 0:\n",
        "        with torch.no_grad():\n",
        "            for A, B in val_loader:\n",
        "                A = A.to(device).float()\n",
        "                B = B.to(device).float()\n",
        "                outputs = siamese_net(A, B).squeeze()\n",
        "                val_loss = criterion(outputs, torch.norm(A - B, dim=1))\n",
        "        counter.append(epoch)\n",
        "        train_loss_list.append(loss.item())\n",
        "        val_loss_list.append(val_loss.item())\n",
        "        print(f'Epoch {epoch} | Train Loss: {loss.item():.5f} | Val Loss: {val_loss.item():.5f}')\n",
        "\n",
        "# Show charts\n",
        "plt.plot(counter,train_loss_list, label='Train Loss')\n",
        "plt.plot(counter,val_loss_list, label='Val Loss')\n",
        "\n",
        "# Test the model\n",
        "# Test the model\n",
        "with torch.no_grad():\n",
        "    for A, B in test_loader:\n",
        "        A = A.to(device).float()\n",
        "        B = B.to(device).float()\n",
        "        outputs = siamese_net(A, B).squeeze()\n",
        "        test_loss = criterion(outputs,  torch.norm(A - B, dim=1))\n",
        "    print(f'Test Loss: {test_loss.item():.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "id": "oywHvINnn50r",
        "outputId": "1bfe65be-0615-49d7-e713-23dbfb972b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Train Loss: 0.09828 | Val Loss: 0.11144\n",
            "Epoch 2 | Train Loss: 0.03965 | Val Loss: 0.04076\n",
            "Epoch 4 | Train Loss: 0.02538 | Val Loss: 0.01994\n",
            "Epoch 6 | Train Loss: 0.01343 | Val Loss: 0.02086\n",
            "Epoch 8 | Train Loss: 0.01152 | Val Loss: 0.02113\n",
            "Epoch 10 | Train Loss: 0.00952 | Val Loss: 0.01275\n",
            "Epoch 12 | Train Loss: 0.01035 | Val Loss: 0.01283\n",
            "Epoch 14 | Train Loss: 0.00694 | Val Loss: 0.00792\n",
            "Epoch 16 | Train Loss: 0.00793 | Val Loss: 0.00735\n",
            "Epoch 18 | Train Loss: 0.00522 | Val Loss: 0.00737\n",
            "Epoch 20 | Train Loss: 0.00556 | Val Loss: 0.00775\n",
            "Epoch 22 | Train Loss: 0.00610 | Val Loss: 0.00739\n",
            "Epoch 24 | Train Loss: 0.00460 | Val Loss: 0.01051\n",
            "Epoch 26 | Train Loss: 0.00572 | Val Loss: 0.00929\n",
            "Epoch 28 | Train Loss: 0.00453 | Val Loss: 0.00891\n",
            "Epoch 30 | Train Loss: 0.00420 | Val Loss: 0.00570\n",
            "Epoch 32 | Train Loss: 0.00272 | Val Loss: 0.00696\n",
            "Epoch 34 | Train Loss: 0.00471 | Val Loss: 0.00654\n",
            "Epoch 36 | Train Loss: 0.00371 | Val Loss: 0.00962\n",
            "Epoch 38 | Train Loss: 0.00356 | Val Loss: 0.00642\n",
            "Epoch 40 | Train Loss: 0.00408 | Val Loss: 0.00667\n",
            "Epoch 42 | Train Loss: 0.00560 | Val Loss: 0.00483\n",
            "Epoch 44 | Train Loss: 0.00366 | Val Loss: 0.00639\n",
            "Epoch 46 | Train Loss: 0.00386 | Val Loss: 0.00620\n",
            "Epoch 48 | Train Loss: 0.00334 | Val Loss: 0.00721\n",
            "Test Loss: 0.00919\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KDTree(object):\n",
        "\n",
        "    \"\"\"\n",
        "    A super short KD-Tree for points...\n",
        "    so concise that you can copypasta into your homework\n",
        "    without arousing suspicion.\n",
        "\n",
        "    This implementation only supports Euclidean distance.\n",
        "\n",
        "    The points can be any array-like type, e.g:\n",
        "        lists, tuples, numpy arrays.\n",
        "\n",
        "    Usage:\n",
        "    1. Make the KD-Tree:\n",
        "        `kd_tree = KDTree(points, dim)`\n",
        "    2. You can then use `get_knn` for k nearest neighbors or\n",
        "       `get_nearest` for the nearest neighbor\n",
        "\n",
        "    points are be a list of points: [[0, 1, 2], [12.3, 4.5, 2.3], ...]\n",
        "    \"\"\"\n",
        "    def __init__(self, points, dim,dist_sq_func=None):\n",
        "        \"\"\"Makes the KD-Tree for fast lookup.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        points : list<point>\n",
        "            A list of points.\n",
        "        dim : int\n",
        "            The dimension of the points.\n",
        "        dist_sq_func : function(point, point), optional\n",
        "            A function that returns the squared Euclidean distance\n",
        "            between the two points.\n",
        "            If omitted, it uses the default implementation.\n",
        "        \"\"\"\n",
        "\n",
        "        if dist_sq_func is None:\n",
        "            dist_sq_func = lambda a, b: sum((x - b[i]) ** 2\n",
        "                for i, x in enumerate(a))\n",
        "\n",
        "        def sort_tensor(t, col):\n",
        "            return t[t[:,col].sort()[1]]\n",
        "        def make(points, i=0):\n",
        "            if len(points) > 1:\n",
        "                sort_tensor(points,i)\n",
        "                i = (i + 1) % dim\n",
        "                m = len(points) >> 1\n",
        "                return [make(points[:m], i), make(points[m + 1:], i),\n",
        "                    points[m]]\n",
        "            if len(points) == 1:\n",
        "                return [None, None, points[0]]\n",
        "\n",
        "        def add_point(node, point, i=0):\n",
        "            if node is not None:\n",
        "                dx = node[2][i] - point[i]\n",
        "                for j, c in ((0, dx >= 0), (1, dx < 0)):\n",
        "                    if c and node[j] is None:\n",
        "                        node[j] = [None, None, point]\n",
        "                    elif c:\n",
        "                        add_point(node[j], point, (i + 1) % dim)\n",
        "\n",
        "        import heapq\n",
        "        def get_knn(node, point, k, return_dist_sq, heap, i=0, tiebreaker=1):\n",
        "            if node is not None:\n",
        "                dist_sq = dist_sq_func(point, node[2])\n",
        "                dx = node[2][i] - point[i]\n",
        "                if len(heap) < k:\n",
        "                    heapq.heappush(heap, (-dist_sq, tiebreaker, node[2]))\n",
        "                elif dist_sq < -heap[0][0]:\n",
        "                    heapq.heappushpop(heap, (-dist_sq, tiebreaker, node[2]))\n",
        "                i = (i + 1) % dim\n",
        "                # Goes into the left branch, then the right branch if needed\n",
        "                for b in (dx < 0, dx >= 0)[:1 + (dx * dx < -heap[0][0])]:\n",
        "                    get_knn(node[b], point, k, return_dist_sq,\n",
        "                        heap, i, (tiebreaker << 1) | b)\n",
        "            if tiebreaker == 1:\n",
        "                return [(-h[0], h[2]) if return_dist_sq else h[2]\n",
        "                    for h in sorted(heap)][::-1]\n",
        "\n",
        "        def walk(node):\n",
        "            if node is not None:\n",
        "                for j in 0, 1:\n",
        "                    for x in walk(node[j]):\n",
        "                        yield x\n",
        "                yield node[2]\n",
        "        self._add_point = add_point\n",
        "        self._get_knn = get_knn\n",
        "        self._root = make(points)\n",
        "        self._walk = walk\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self._walk(self._root)\n",
        "\n",
        "    def add_point(self, point):\n",
        "        \"\"\"Adds a point to the kd-tree.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        point : array-like\n",
        "            The point.\n",
        "        \"\"\"\n",
        "        if self._root is None:\n",
        "            self._root = [None, None, point]\n",
        "        else:\n",
        "            self._add_point(self._root, point)\n",
        "\n",
        "    def get_knn(self, point, k, return_dist_sq=True):\n",
        "        \"\"\"Returns k nearest neighbors.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        point : array-like\n",
        "            The point.\n",
        "        k: int\n",
        "            The number of nearest neighbors.\n",
        "        return_dist_sq : boolean\n",
        "            Whether to return the squared Euclidean distances.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list<array-like>\n",
        "            The nearest neighbors.\n",
        "            If `return_dist_sq` is true, the return will be:\n",
        "                [(dist_sq, point), ...]\n",
        "            else:\n",
        "                [point, ...]\n",
        "        \"\"\"\n",
        "        return self._get_knn(self._root, point, k, return_dist_sq, [])\n",
        "\n",
        "    def get_nearest(self, point, return_dist_sq=True):\n",
        "        \"\"\"Returns the nearest neighbor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        point : array-like\n",
        "            The point.\n",
        "        return_dist_sq : boolean\n",
        "            Whether to return the squared Euclidean distance.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        array-like\n",
        "            The nearest neighbor.\n",
        "            If the tree is empty, returns `None`.\n",
        "            If `return_dist_sq` is true, the return will be:\n",
        "                (dist_sq, point)\n",
        "            else:\n",
        "                point\n",
        "        \"\"\"\n",
        "        l = self._get_knn(self._root, point, 1, return_dist_sq, [])\n",
        "        return l[0] if len(l) else None"
      ],
      "metadata": {
        "id": "fGAX9lpKljar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.random.normal(loc=0, scale=1, size=(3,DIM))\n",
        "#a = torch.tensor(a).to(device)\n",
        "\n",
        "def dist_sq(a, b):\n",
        "    return siamese_net(torch.tensor(a).float(), torch.tensor(b).float()).item()"
      ],
      "metadata": {
        "id": "uJN8Tt9z1SOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.tensor(a).to(device)\n",
        "print(dist_sq(b[0].to(device), b[1].to(device)))\n",
        "print(torch.norm(b[0]-b[1]).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v40bduVr3viV",
        "outputId": "25d4d325-b93b-47b5-a2cd-ace7e82be828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7087277173995972\n",
            "1.6930580002031852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-99beb0c5dffc>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return siamese_net(torch.tensor(a).float(), torch.tensor(b).float()).item()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_tensor(t, col):\n",
        "    return t[t[:,col].sort()[1]]\n",
        "print(b)\n",
        "print(sort_tensor(b, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ww7Ooi043P6",
        "outputId": "6a1ddcda-34ff-4e5e-e825-0b2113cca9f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2000,  1.1227,  0.3647,  0.2223,  0.1345],\n",
            "        [ 1.0494,  1.8829,  0.2816,  1.3538, -0.3945],\n",
            "        [-1.7795, -0.2063,  1.9518, -1.1714, -0.5758]], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "tensor([[-1.7795, -0.2063,  1.9518, -1.1714, -0.5758],\n",
            "        [ 1.0494,  1.8829,  0.2816,  1.3538, -0.3945],\n",
            "        [ 0.2000,  1.1227,  0.3647,  0.2223,  0.1345]], device='cuda:0',\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dh7BpmYU48pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kd_tree = KDTree(points = b, dim = DIM,dist_sq_func=dist_sq)"
      ],
      "metadata": {
        "id": "O0ZCuVHx3xJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_point = np.random.normal(loc=0, scale=1, size=(1,DIM))\n",
        "print(new_point)\n",
        "new_point = torch.tensor(new_point[0]).to(device)\n",
        "kd_tree.add_point(new_point)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu4IHcRO37GJ",
        "outputId": "26b7c490-7905-4423-819e-917cda06d9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.88084321 -0.60894597  1.07332512  1.55747779 -0.72482855]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN Classifier using KDTree\n",
        "class KNNClassifier(object):\n",
        "    def __init__(self, siamese_net, k=1):\n",
        "        self.k = k\n",
        "        self.kd_tree = None\n",
        "        self.labels = None\n",
        "\n",
        "\n",
        "    def dist_sq(a, b):\n",
        "        return siamese_net(torch.tensor(a).float(), torch.tensor(b).float()).item()\n",
        "    def fit(self, X, y):\n",
        "        self.kd_tree = KDTree(X, X.shape[1])\n",
        "        self.labels = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = []\n",
        "        for x in X:\n",
        "            neighbors = self.kd_tree.get_knn(x, self.k, return_dist_sq=False) #[label[..,..,..,..,..]]\n",
        "            y_pred.append(np.argmax(np.bincount(self.labels[neighbors])))\n",
        "        return np.array(y_pred)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        return np.mean(y_pred == y)\n",
        "\n",
        "# Create a KNNClassifier instance\n",
        "knn = KNNClassifier(k=3, siamese_net = siamese_net)\n",
        "\n",
        "\n",
        "# test the classifier\n",
        "a = np.random.normal(loc=0, scale=1, size=(100,DIM))\n",
        "b = np.random.normal(loc=0, scale=1, size=(100,DIM))\n",
        "X = np.concatenate((a, b), axis=0)\n",
        "y = np.array([0]*100 + [1]*100)\n",
        "\n",
        "X = torch.tensor(X).to(device).float()\n",
        "y = torch.tensor(y).to(device)\n",
        "knn.fit(X, y)\n",
        "print(knn.score(X, y))"
      ],
      "metadata": {
        "id": "bXE0L1XQ8592"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "[[\n",
        "   label,\n",
        "   [1,2,3,4]\n",
        "],\n",
        "[\n",
        "  label,\n",
        "  [2,3,4,5]\n",
        "]\n",
        "]\n",
        "'''\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "X, Y = load_diabetes(return_X_y=True)\n",
        "dataset = []\n",
        "for x, y in zip(X, Y):\n",
        "    dataset.append(torch.nested.nested_tensor([torch.tensor(y).view(1,1), torch.tensor(x).view(X.shape[1],1)]))\n",
        "dataset[0]"
      ],
      "metadata": {
        "id": "WlYtGGXz9xFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7b39d8-67bd-42f8-f3a9-132600b2ff49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-8222a1f29c5c>:20: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  dataset.append(torch.nested.nested_tensor([torch.tensor(y).view(1,1), torch.tensor(x).view(X.shape[1],1)]))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nested_tensor([\n",
              "  tensor([[151.]], dtype=torch.float64),\n",
              "  tensor([[ 0.0381],\n",
              "          [ 0.0507],\n",
              "          [ 0.0617],\n",
              "          [ 0.0219],\n",
              "          [-0.0442],\n",
              "          [-0.0348],\n",
              "          [-0.0434],\n",
              "          [-0.0026],\n",
              "          [ 0.0199],\n",
              "          [-0.0176]], dtype=torch.float64)\n",
              "])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RrJ16mD5M3T1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}